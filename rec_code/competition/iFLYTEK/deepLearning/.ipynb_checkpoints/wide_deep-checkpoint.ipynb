{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide&Deep 模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Embedding, Concatenate, Dropout, Input, Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sparseFeature(feat, feat_num, embed_dim=4):\n",
    "    \"\"\"\n",
    "    create dictionary for sparse feature\n",
    "    :param feat: feature name\n",
    "    :param feat_num: the total number of sparse features that do not repeat\n",
    "    :param embed_dim: embedding dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}\n",
    "\n",
    "def denseFeature(feat):\n",
    "    \"\"\"\n",
    "    create dictionary for dense feature\n",
    "    :param feat: dense feature name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat}\n",
    "\n",
    "\n",
    "def create_criteo_dataset(file_train, file_test, dense_features, sparse_features,\n",
    "                          embed_dim=8, read_part=False, sample_num=100000, test_size=0.2):\n",
    "\n",
    "    # 训练数据\n",
    "    df_train = pd.read_csv(file_train)\n",
    "    # 测试数据\n",
    "    df_apply_new = pd.read_csv(file_test)\n",
    "    # 合并训练集，验证集\n",
    "    data = pd.concat([df_train, df_apply_new], axis=0, ignore_index=True)\n",
    "    data['label'] = data['label'].fillna(str(-1))\n",
    "\n",
    "    def clean_data(string):\n",
    "        # 对数据清洗\n",
    "        string = re.sub(r\"[^0-9()]\", \"\", string)\n",
    "        return string.strip().lower()\n",
    "\n",
    "    # ==============Age ===================\n",
    "    # 处理Age\n",
    "    # 缺失值填充\n",
    "    data['age'] = data['age'].fillna(0)\n",
    "    a = data['age'].copy()\n",
    "    a = a.apply(lambda x: str(x).lower())\n",
    "    # 统一字符类型转化成str()\n",
    "    a = a.apply(lambda x: clean_data(x))\n",
    "    data['age'] = a\n",
    "\n",
    "    # ==============Gender ===================\n",
    "    data['gender'] = data['gender'].fillna(str(2))\n",
    "    g = data['gender'].copy()\n",
    "    # 统一字符类型转化成str()\n",
    "    g = g.apply(lambda x: str(x).lower())\n",
    "    g = g.apply(lambda x: clean_data(x))\n",
    "    data['gender'] = g\n",
    "\n",
    "    # ==============appid_num ===================\n",
    "    appid_num = data['appid']\n",
    "    def get_appid_num(string):\n",
    "        # 对数据清洗\n",
    "        string = string.split(',')\n",
    "        return len(string)\n",
    "\n",
    "    appid_num = appid_num.apply(lambda x: get_appid_num(x))\n",
    "    data['appid_num'] = appid_num\n",
    "    dense_features = dense_features + ['appid_num']\n",
    "\n",
    "\n",
    "    # ==============appid split ===================\n",
    "    # 删除掉一些字符\n",
    "    a = lambda s: re.sub('[^A-Za-z0-9 ]+', ' ', s)\n",
    "    data_str = map(a, data[sparse_features])\n",
    "    data[sparse_features] = list(data_str)\n",
    "\n",
    "    df_sparse_features = data[sparse_features].str.split(' ', expand=True)\n",
    "    data_df = data[dense_features]\n",
    "\n",
    "    for i in range(1, 30):\n",
    "        data_df['sparse_' + str(i)] = df_sparse_features.iloc[:, i].str.strip()\n",
    "\n",
    "    # ==============将sparse_features转化成数字 ===================\n",
    "    data_df.replace(to_replace='None', value=np.nan).dropna(axis=1, how='all', inplace=True)\n",
    "    sparse_ = [val for val in data_df.columns if 'sparse_' in val]\n",
    "    data_df[sparse_] = data_df[sparse_].fillna('-1')\n",
    "\n",
    "    # 将sparse_features转化成数字，用fit_transform()函数相同的字符转化成相同的数字。\n",
    "    # labelencoder 转化\n",
    "    encoder = ['province', 'city', 'model']\n",
    "    for feat in sparse_ + encoder:\n",
    "        le = LabelEncoder()\n",
    "        data_df[feat] = le.fit_transform(data_df[feat])\n",
    "\n",
    "\n",
    "    # ==============Feature Engineering===================\n",
    "    # ====================================================\n",
    "    dense_features = [feat for feat in data_df.columns if feat not in sparse_ + ['label']]\n",
    "\n",
    "\n",
    "    # 统计dense_features、sparse_features每个特征的个数和\n",
    "    feature_columns = [[denseFeature(feat) for feat in dense_features]] + \\\n",
    "                      [[sparseFeature(feat, len(data_df[feat].unique()), embed_dim=embed_dim)\n",
    "                        for feat in sparse_]]\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    \"\"\"\n",
    "    ### 本次案例中：将所有的样本作为训练集。\n",
    "    ### 使用全部的样本作为训练集，通过交叉验证的方法划分为：测试集+验证集\n",
    "    \"\"\"\n",
    "    data_df_1 = data_df[data_df.label != '-1']  # data.click != -1的样本为训练的样本集合\n",
    "    train, test = train_test_split(data_df_1, test_size=test_size)\n",
    "\n",
    "    train_X = [train[dense_features].values.astype('int32'), train[sparse_].values.astype('int32')]\n",
    "    train_y = train['label'].values.astype('int32')\n",
    "    test_X = [test[dense_features].values.astype('int32'), test[sparse_].values.astype('int32')]\n",
    "    test_y = test['label'].values.astype('int32')\n",
    "\n",
    "\n",
    "    # 划分需要预测的样本集\n",
    "    data_df_2 = data_df[data_df.label == '-1']  # data.click == -1的样本为需要预测的样本集合\n",
    "    total_test = [data_df_2[dense_features].values.astype('int32'), train[sparse_].values.astype('int32')]\n",
    "\n",
    "    return feature_columns, (train_X, train_y), (test_X, test_y), total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python\\1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3263: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "F:\\Python\\1\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "read_part = True\n",
    "sample_num = 6000000\n",
    "test_size = 0.2\n",
    "\n",
    "embed_dim = 8\n",
    "dnn_dropout = 0.5\n",
    "hidden_units = [256, 128, 64]\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "# you can modify your file path\n",
    "file_train = '../data/train.csv'\n",
    "file_test = '../data/apply_new.csv'\n",
    "\n",
    "dense_features = ['label', 'gender', 'age', 'city', 'province', 'model']\n",
    "sparse_features = \"appid\"\n",
    "\n",
    "# ========================== Create dataset =======================\n",
    "feature_columns, train, test, vail = create_criteo_dataset(file_train=file_train,\n",
    "                                                           file_test=file_test,\n",
    "                                                           dense_features=dense_features,\n",
    "                                                           sparse_features=sparse_features,\n",
    "                                                           embed_dim=embed_dim,\n",
    "                                                           read_part=read_part,\n",
    "                                                           sample_num=sample_num,\n",
    "                                                           test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    \"\"\"\n",
    "    Linear Part\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.dense = Dense(1, activation=None)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        result = self.dense(inputs)\n",
    "        return result\n",
    "\n",
    "\n",
    "class DNN(Layer):\n",
    "    \"\"\"\n",
    "\tDeep Neural Network\n",
    "\t\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_units, activation='relu', dropout=0.):\n",
    "        \"\"\"\n",
    "\t\t:param hidden_units: A list. Neural network hidden units.\n",
    "\t\t:param activation: A string. Activation function of dnn.\n",
    "\t\t:param dropout: A scalar. Dropout number.\n",
    "\t\t\"\"\"\n",
    "        super(DNN, self).__init__()\n",
    "        self.dnn_network = [Dense(units=unit, activation=activation) for unit in hidden_units]\n",
    "        self.dropout = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x = inputs\n",
    "        for dnn in self.dnn_network:\n",
    "            x = dnn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class WideDeep(tf.keras.Model):\n",
    "    def __init__(self, feature_columns, hidden_units, activation='relu',\n",
    "                 dnn_dropout=0., embed_reg=1e-4):\n",
    "        \"\"\"\n",
    "        Wide&Deep\n",
    "        :param feature_columns: A list. dense_feature_columns + sparse_feature_columns\n",
    "        :param hidden_units: A list. Neural network hidden units.\n",
    "        :param activation: A string. Activation function of dnn.\n",
    "        :param dnn_dropout: A scalar. Dropout of dnn.\n",
    "        :param embed_reg: A scalar. The regularizer of embedding.\n",
    "        \"\"\"\n",
    "        super(WideDeep, self).__init__()\n",
    "        self.dnn_network = DNN(hidden_units, activation, dnn_dropout)\n",
    "        self.linear = Linear()\n",
    "        self.final_dense = Dense(1, activation=None)\n",
    "        self.dense_feature_columns, self.sparse_feature_columns = feature_columns\n",
    "        self.embed_layers = {\n",
    "            'embed_' + str(i): Embedding(input_dim=feat['feat_num'],\n",
    "                                         input_length=1,\n",
    "                                         output_dim=feat['embed_dim'],\n",
    "                                         embeddings_initializer='random_uniform',\n",
    "                                         embeddings_regularizer=l2(embed_reg))\n",
    "            for i, feat in enumerate(self.sparse_feature_columns)\n",
    "        }\n",
    "\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        dense_inputs, sparse_inputs = inputs\n",
    "        sparse_embed = tf.concat([self.embed_layers['embed_{}'.format(i)](sparse_inputs[:, i])\n",
    "                                  for i in range(sparse_inputs.shape[1])], axis=-1)\n",
    "        dense_inputs = tf.cast(dense_inputs, dtype=tf.float32)  # dense_inputs 类型转化成float\n",
    "        x = tf.concat([sparse_embed, dense_inputs], axis=-1)\n",
    "\n",
    "        # Wide\n",
    "        wide_out = self.linear(dense_inputs)\n",
    "        # Deep\n",
    "        deep_out = self.dnn_network(x)\n",
    "        deep_out = self.final_dense(deep_out)\n",
    "        # out\n",
    "        outputs = tf.nn.sigmoid(0.5 * (wide_out + deep_out))\n",
    "        return outputs\n",
    "\n",
    "    def summary(self, **kwargs):\n",
    "        dense_inputs = Input(shape=(len(self.dense_feature_columns),), dtype=tf.int32)\n",
    "        sparse_inputs = Input(shape=(len(self.sparse_feature_columns),), dtype=tf.int32)\n",
    "        keras.Model(inputs=[dense_inputs, sparse_inputs],\n",
    "                    outputs=self.call([dense_inputs, sparse_inputs])).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 29)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_16 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_17 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_18 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_19 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_20 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_21 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_22 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_23 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_26 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_28 (T [(None,)]            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 8)            205152      tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 8)            206968      tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 8)            206816      tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 8)            206688      tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 8)            207176      tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 8)            206960      tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 8)            205888      tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 8)            204152      tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 8)            205720      tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 8)            205240      tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 8)            201984      tf_op_layer_strided_slice_10[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 8)            202240      tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 8)            203624      tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 8)            201192      tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 8)            198352      tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 8)            198232      tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 8)            196968      tf_op_layer_strided_slice_16[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 8)            195968      tf_op_layer_strided_slice_17[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 8)            193784      tf_op_layer_strided_slice_18[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 8)            193600      tf_op_layer_strided_slice_19[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 8)            191792      tf_op_layer_strided_slice_20[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 8)            189888      tf_op_layer_strided_slice_21[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 8)            186264      tf_op_layer_strided_slice_22[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 8)            185848      tf_op_layer_strided_slice_23[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 8)            183200      tf_op_layer_strided_slice_24[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 8)            180040      tf_op_layer_strided_slice_25[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 8)            179080      tf_op_layer_strided_slice_26[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 8)            178552      tf_op_layer_strided_slice_27[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 8)            176176      tf_op_layer_strided_slice_28[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast (TensorFlowOpL [(None, 6)]          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 232)]        0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "                                                                 embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "                                                                 embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "                                                                 embedding_21[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "                                                                 embedding_23[0][0]               \n",
      "                                                                 embedding_24[0][0]               \n",
      "                                                                 embedding_25[0][0]               \n",
      "                                                                 embedding_26[0][0]               \n",
      "                                                                 embedding_27[0][0]               \n",
      "                                                                 embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 238)]        0           tf_op_layer_concat[0][0]         \n",
      "                                                                 tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 64)           102336      tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "linear (Linear)                 (None, 1)            7           tf_op_layer_Cast[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add (TensorFlowOpLa [(None, 1)]          0           linear[0][0]                     \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_add[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorFlow [(None, 1)]          0           tf_op_layer_mul[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 5,799,952\n",
      "Trainable params: 5,799,952\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216000 samples, validate on 24000 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python\\1\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216000/216000 [==============================] - 45s 207us/sample - loss: 3.0622 - auc: 0.5397 - val_loss: 0.9819 - val_auc: 0.6437\n",
      "Epoch 2/30\n",
      "216000/216000 [==============================] - 42s 195us/sample - loss: 1.3709 - auc: 0.6271 - val_loss: 0.7771 - val_auc: 0.6941\n",
      "Epoch 3/30\n",
      "216000/216000 [==============================] - 41s 188us/sample - loss: 0.9451 - auc: 0.6865 - val_loss: 0.7422 - val_auc: 0.7007\n",
      "Epoch 4/30\n",
      "177664/216000 [=======================>......] - ETA: 7s - loss: 0.7265 - auc: 0.7495"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================== Create dataset =======================\n",
    "train_X, train_y = train\n",
    "test_X, test_y = test\n",
    "\n",
    "# ============================Build Model==========================\n",
    "model = WideDeep(feature_columns, hidden_units=hidden_units, dnn_dropout=dnn_dropout)\n",
    "model.summary()\n",
    "# ============================model checkpoint======================\n",
    "# check_path = '../save/wide_deep_weights.epoch_{epoch:04d}.val_loss_{val_loss:.4f}.ckpt'\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(check_path, save_weights_only=True,\n",
    "#                                                 verbose=1, period=5)\n",
    "# ============================Compile============================\n",
    "model.compile(loss=binary_crossentropy, optimizer=Adam(learning_rate=learning_rate),\n",
    "              metrics=[AUC()])\n",
    "# ==============================Fit==============================\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=epochs,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)],  # checkpoint\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1\n",
    ")\n",
    "# ===========================Test==============================\n",
    "print('test AUC: %f' % model.evaluate(test_X, test_y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Python学习)",
   "language": "python",
   "name": "pycharm-a0a80560"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
