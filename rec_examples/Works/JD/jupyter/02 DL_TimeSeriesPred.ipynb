{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad62c14-b7e2-4ae2-88e0-ec21a5c5e9a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- 1 测试jd cross\n",
    "- 2 DCN DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a7027c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-14T03:53:31.174666Z",
     "start_time": "2022-06-14T03:53:28.183110Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import platform\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d2c82c-f7a8-4d11-b30b-bc1bd83e8c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695200, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>unit</th>\n",
       "      <th>qty</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>geography_level_1</th>\n",
       "      <th>geography_level_2</th>\n",
       "      <th>geography_level_3</th>\n",
       "      <th>...</th>\n",
       "      <th>geo1mean14</th>\n",
       "      <th>geo2mean14</th>\n",
       "      <th>geo3mean14</th>\n",
       "      <th>pro1mean14</th>\n",
       "      <th>pro2mean14</th>\n",
       "      <th>geo1median14</th>\n",
       "      <th>geo2median14</th>\n",
       "      <th>geo3median14</th>\n",
       "      <th>pro1median14</th>\n",
       "      <th>pro2median14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>386</td>\n",
       "      <td>11926.8286</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>463</td>\n",
       "      <td>6282.7266</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>273</td>\n",
       "      <td>285.3290</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>520</td>\n",
       "      <td>6672.6452</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>480</td>\n",
       "      <td>15204.5902</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts  unit         qty  year  month  day  week  geography_level_1  \\\n",
       "0    2018-06-04   386  11926.8286  2018      6    4     0                  5   \n",
       "1100 2018-06-04   463   6282.7266  2018      6    4     0                  0   \n",
       "2200 2018-06-04   273    285.3290  2018      6    4     0                  0   \n",
       "3300 2018-06-04   520   6672.6452  2018      6    4     0                  1   \n",
       "4400 2018-06-04   480  15204.5902  2018      6    4     0                  7   \n",
       "\n",
       "      geography_level_2  geography_level_3  ...  geo1mean14  geo2mean14  \\\n",
       "0                    12                 11  ...         NaN         NaN   \n",
       "1100                  3                 75  ...         NaN         NaN   \n",
       "2200                 10                  7  ...         NaN         NaN   \n",
       "3300                 11                 23  ...         NaN         NaN   \n",
       "4400                  4                 76  ...         NaN         NaN   \n",
       "\n",
       "      geo3mean14  pro1mean14  pro2mean14  geo1median14  geo2median14  \\\n",
       "0            NaN         NaN         NaN           NaN           NaN   \n",
       "1100         NaN         NaN         NaN           NaN           NaN   \n",
       "2200         NaN         NaN         NaN           NaN           NaN   \n",
       "3300         NaN         NaN         NaN           NaN           NaN   \n",
       "4400         NaN         NaN         NaN           NaN           NaN   \n",
       "\n",
       "      geo3median14  pro1median14  pro2median14  \n",
       "0              NaN           NaN           NaN  \n",
       "1100           NaN           NaN           NaN  \n",
       "2200           NaN           NaN           NaN  \n",
       "3300           NaN           NaN           NaN  \n",
       "4400           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load traindataset\n",
    "with open(\"../output/traindataset.pkl\", 'rb') as fo:     # 读取pkl文件数据\n",
    "    traindataset = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "traindataset[\"ts\"] = traindataset[\"ts\"].apply(lambda x: pd.to_datetime(x))\n",
    "print(traindataset.shape)\n",
    "traindataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290f3ae1-d1ed-4dbe-bb18-5b51e667fea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 695200 entries, 0 to 695199\n",
      "Data columns (total 48 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   ts                 695200 non-null  datetime64[ns]\n",
      " 1   unit               695200 non-null  int64         \n",
      " 2   qty                345316 non-null  float64       \n",
      " 3   year               695200 non-null  int64         \n",
      " 4   month              695200 non-null  int64         \n",
      " 5   day                695200 non-null  int64         \n",
      " 6   week               695200 non-null  int64         \n",
      " 7   geography_level_1  695200 non-null  int64         \n",
      " 8   geography_level_2  695200 non-null  int64         \n",
      " 9   geography_level_3  695200 non-null  int64         \n",
      " 10  product_level_1    695200 non-null  int64         \n",
      " 11  product_level_2    695200 non-null  int64         \n",
      " 12  unit_pro           695200 non-null  int64         \n",
      " 13  geo_pro            695200 non-null  int64         \n",
      " 14  weight             695200 non-null  float64       \n",
      " 15  last14max          344717 non-null  float64       \n",
      " 16  last14min          344717 non-null  float64       \n",
      " 17  last14std          344085 non-null  float64       \n",
      " 18  last14mean         344717 non-null  float64       \n",
      " 19  last14median       344717 non-null  float64       \n",
      " 20  last14sum          694568 non-null  float64       \n",
      " 21  last7max           344712 non-null  float64       \n",
      " 22  last7min           344712 non-null  float64       \n",
      " 23  last7std           344068 non-null  float64       \n",
      " 24  last7mean          344712 non-null  float64       \n",
      " 25  last7median        344712 non-null  float64       \n",
      " 26  last7sum           694568 non-null  float64       \n",
      " 27  last3max           344695 non-null  float64       \n",
      " 28  last3min           344695 non-null  float64       \n",
      " 29  last3std           344051 non-null  float64       \n",
      " 30  last3mean          344695 non-null  float64       \n",
      " 31  last3median        344695 non-null  float64       \n",
      " 32  last3sum           694568 non-null  float64       \n",
      " 33  last3value         344684 non-null  object        \n",
      " 34  last1value         694568 non-null  float64       \n",
      " 35  last2mean          344690 non-null  float64       \n",
      " 36  last2sum           694568 non-null  float64       \n",
      " 37  last2value         344684 non-null  object        \n",
      " 38  geo1mean14         345294 non-null  float64       \n",
      " 39  geo2mean14         345267 non-null  float64       \n",
      " 40  geo3mean14         345198 non-null  float64       \n",
      " 41  pro1mean14         344949 non-null  float64       \n",
      " 42  pro2mean14         344946 non-null  float64       \n",
      " 43  geo1median14       345294 non-null  float64       \n",
      " 44  geo2median14       345267 non-null  float64       \n",
      " 45  geo3median14       345198 non-null  float64       \n",
      " 46  pro1median14       344949 non-null  float64       \n",
      " 47  pro2median14       344946 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(33), int64(12), object(2)\n",
      "memory usage: 259.9+ MB\n"
     ]
    }
   ],
   "source": [
    "traindataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518f4aa-da70-42bd-a9b0-58da20b05175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcc0c690-62e1-4db8-8b3e-41bc0af90b69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 模型训练\n",
    "\n",
    "\n",
    "- 1.JD_cross2\n",
    "- 2.DeepFM\n",
    "- ref  \n",
    "https://github.com/PENGZhaoqing/TimeSeriesPrediction  \n",
    "https://github.com/gabrielpreda/Kaggle/blob/master/SantanderCustomerTransactionPrediction/starter-code-saving-and-loading-lgb-xgb-cb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0bf02cb-20ed-44a1-804a-a5696ef14292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features\n",
    "sparse_features = ['unit', 'year', 'month', 'day', 'week', 'geography_level_1', 'geography_level_2', 'geography_level_3', \n",
    "                   'product_level_1', 'product_level_2', 'unit_pro', 'geo_pro']\n",
    "dense_features = ['weight',\n",
    "       'last14max', 'last14min', 'last14std', 'last14mean', 'last14median',\n",
    "       'last14sum', 'last7max', 'last7min', 'last7std', 'last7mean',\n",
    "       'last7median', 'last7sum', 'last3max', 'last3min', 'last3std',\n",
    "       'last3mean', 'last3median', 'last3sum', 'last3value', 'last1value', 'last2mean',\n",
    "       'last2sum', 'last2value', 'geo1mean14', 'geo2mean14', 'geo3mean14', 'pro1mean14',\n",
    "       'pro2mean14', 'geo1median14', 'geo2median14', 'geo3median14',\n",
    "       'pro1median14', 'pro2median14']\n",
    "\n",
    "target = ['qty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bfd1d6ea-78a6-468e-8fc9-3d5d661efa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = traindataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f338a97-d873-4d59-ba66-ecedc9a4c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## densce_feature = np.log 处理\n",
    "# dense_log = [name for name in dense_features if name != 'weight']\n",
    "\n",
    "# for name in dense_log:\n",
    "#     dataset[name] = np.log(dataset[name].astype(float) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d2d5f32d-e9db-4cea-92af-a919baf312f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343425, 48)\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# traindataset[:100].loc[~traindataset[:100]['geo1mean14'].isnull()]\n",
    "# traindataset[np.isnan(traindataset['qty'].values)]\n",
    "# traindataset['qty'][np.isinf(traindataset['qty'])] = 0.0 \n",
    "\n",
    "# 替换空值，和选择大于0的数据\n",
    "dataset = dataset.dropna(axis=0, how='any')\n",
    "print(dataset.shape)\n",
    "print(np.isnan(dataset['qty']).any())\n",
    "print(np.isinf(dataset['qty']).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ad837c8-35ad-47aa-93ab-878e5c209751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>unit</th>\n",
       "      <th>qty</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>geography_level_1</th>\n",
       "      <th>geography_level_2</th>\n",
       "      <th>geography_level_3</th>\n",
       "      <th>...</th>\n",
       "      <th>geo1mean14</th>\n",
       "      <th>geo2mean14</th>\n",
       "      <th>geo3mean14</th>\n",
       "      <th>pro1mean14</th>\n",
       "      <th>pro2mean14</th>\n",
       "      <th>geo1median14</th>\n",
       "      <th>geo2median14</th>\n",
       "      <th>geo3median14</th>\n",
       "      <th>pro1median14</th>\n",
       "      <th>pro2median14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>386</td>\n",
       "      <td>11926.8286</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9322.3656</td>\n",
       "      <td>9322.36560</td>\n",
       "      <td>10257.857667</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>9402.9722</td>\n",
       "      <td>9402.9722</td>\n",
       "      <td>11574.9116</td>\n",
       "      <td>7465.9504</td>\n",
       "      <td>7368.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>463</td>\n",
       "      <td>6316.9266</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>11468.3274</td>\n",
       "      <td>6292.42660</td>\n",
       "      <td>6292.426600</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>9257.5354</td>\n",
       "      <td>6292.4266</td>\n",
       "      <td>6292.4266</td>\n",
       "      <td>7465.9504</td>\n",
       "      <td>7368.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>273</td>\n",
       "      <td>290.9290</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11468.3274</td>\n",
       "      <td>12503.50756</td>\n",
       "      <td>12786.431900</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>9257.5354</td>\n",
       "      <td>12262.2442</td>\n",
       "      <td>12769.1319</td>\n",
       "      <td>7465.9504</td>\n",
       "      <td>7368.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>520</td>\n",
       "      <td>6116.8452</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>18160.9770</td>\n",
       "      <td>17557.10800</td>\n",
       "      <td>6594.245200</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>21302.7755</td>\n",
       "      <td>22596.5670</td>\n",
       "      <td>6594.2452</td>\n",
       "      <td>7465.9504</td>\n",
       "      <td>7368.8416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>480</td>\n",
       "      <td>15212.3902</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>11336.2203</td>\n",
       "      <td>11336.22030</td>\n",
       "      <td>11336.220300</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>11335.3203</td>\n",
       "      <td>11335.3203</td>\n",
       "      <td>11335.3203</td>\n",
       "      <td>7465.9504</td>\n",
       "      <td>7368.8416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ts  unit         qty  year  month  day  week  geography_level_1  \\\n",
       "2    2018-06-06   386  11926.8286  2018      6    6     2                  5   \n",
       "1102 2018-06-06   463   6316.9266  2018      6    6     2                  0   \n",
       "2202 2018-06-06   273    290.9290  2018      6    6     2                  0   \n",
       "3302 2018-06-06   520   6116.8452  2018      6    6     2                  1   \n",
       "4402 2018-06-06   480  15212.3902  2018      6    6     2                  7   \n",
       "\n",
       "      geography_level_2  geography_level_3  ...  geo1mean14   geo2mean14  \\\n",
       "2                    12                 11  ...   9322.3656   9322.36560   \n",
       "1102                  3                 75  ...  11468.3274   6292.42660   \n",
       "2202                 10                  7  ...  11468.3274  12503.50756   \n",
       "3302                 11                 23  ...  18160.9770  17557.10800   \n",
       "4402                  4                 76  ...  11336.2203  11336.22030   \n",
       "\n",
       "        geo3mean14    pro1mean14    pro2mean14  geo1median14  geo2median14  \\\n",
       "2     10257.857667  10866.343811  10826.978933     9402.9722     9402.9722   \n",
       "1102   6292.426600  10866.343811  10826.978933     9257.5354     6292.4266   \n",
       "2202  12786.431900  10866.343811  10826.978933     9257.5354    12262.2442   \n",
       "3302   6594.245200  10866.343811  10826.978933    21302.7755    22596.5670   \n",
       "4402  11336.220300  10866.343811  10826.978933    11335.3203    11335.3203   \n",
       "\n",
       "      geo3median14  pro1median14  pro2median14  \n",
       "2       11574.9116     7465.9504     7368.8416  \n",
       "1102     6292.4266     7465.9504     7368.8416  \n",
       "2202    12769.1319     7465.9504     7368.8416  \n",
       "3302     6594.2452     7465.9504     7368.8416  \n",
       "4402    11335.3203     7465.9504     7368.8416  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "da27d1d3-99d3-48c6-9ba7-d0e2734e043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'unit', 'qty', 'year', 'month', 'day', 'week',\n",
       "       'geography_level_1', 'geography_level_2', 'geography_level_3',\n",
       "       'product_level_1', 'product_level_2', 'unit_pro', 'geo_pro', 'weight',\n",
       "       'last14max', 'last14min', 'last14std', 'last14mean', 'last14median',\n",
       "       'last14sum', 'last7max', 'last7min', 'last7std', 'last7mean',\n",
       "       'last7median', 'last7sum', 'last3max', 'last3min', 'last3std',\n",
       "       'last3mean', 'last3median', 'last3sum', 'last3value', 'last1value',\n",
       "       'last2mean', 'last2sum', 'last2value', 'geo1mean14', 'geo2mean14',\n",
       "       'geo3mean14', 'pro1mean14', 'pro2mean14', 'geo1median14',\n",
       "       'geo2median14', 'geo3median14', 'pro1median14', 'pro2median14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d4c302-37be-46f2-abe2-7a725e5b18d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe31354f-7d5e-4106-87ba-917148924d56",
   "metadata": {},
   "source": [
    "## 1.1 JD_cross2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3186cfc-254a-4a84-bd53-c114743b55ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11de4e-2e50-45a8-b642-b656d8892b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec923b4-aef7-4484-b582-1c4d61cda522",
   "metadata": {},
   "source": [
    "## 1.2 DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93e6e5-72f0-4d39-b9ba-d801d94115c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4be4e529-c126-4bae-bbf0-9342752f4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseFeature(feat, feat_num, embed_dim=4):\n",
    "    \"\"\"\n",
    "    create dictionary for sparse feature\n",
    "    :param feat: feature name\n",
    "    :param feat_num: the total number of sparse features that do not repeat\n",
    "    :param embed_dim: embedding dimension\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat, 'feat_num': feat_num, 'embed_dim': embed_dim}\n",
    "\n",
    "\n",
    "def denseFeature(feat):\n",
    "    \"\"\"\n",
    "    create dictionary for dense feature\n",
    "    :param feat: dense feature name\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return {'feat': feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f66300af-3cb1-485e-bbc7-ad6192fc9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 获取test, 便于还原\n",
    "# test = dataset[dataset.ts > pd.to_datetime(\"20210301\")]\n",
    "# max_value = np.max(test['qty'].values)\n",
    "# min_value = np.min(test['qty'].values)\n",
    "\n",
    "# print(max_value, min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b96e370c-36e4-4836-ad53-2ee73d631fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=32\n",
    "test_size=0.2\n",
    "\n",
    "# encoder done!!!\n",
    "encoder = ['geography_level_1','geography_level_2','geography_level_3','product_level_1','product_level_2']\n",
    "unit_all = [ 'unit_pro', 'geo_pro', 'unit']\n",
    "\n",
    "# 1 Encode \n",
    "for feat in sparse_features:\n",
    "    if feat not in encoder+unit_all:\n",
    "        le = LabelEncoder()\n",
    "        dataset[feat] = le.fit_transform(dataset[feat])\n",
    "\n",
    "# 2 log10()\n",
    "# mms = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset[dense_features] = mms.fit_transform(dataset[dense_features])\n",
    "dense_features_log = [name for name in dense_features if name != 'weight'] + target\n",
    "for feat in dense_features_log:\n",
    "    if feat == 'qty':\n",
    "        dataset[feat] = np.log(dataset[feat].astype(float) + 1)\n",
    "    # dataset[feat] = np.log10(dataset[feat].astype(float) + 1)\n",
    "    dataset[feat] = dataset[feat].astype(float)\n",
    "\n",
    "feature_columns = [[denseFeature(feat) for feat in dense_features]] + \\\n",
    "                  [[sparseFeature(feat, len(dataset[feat].unique()), embed_dim=embed_dim)\n",
    "                    for feat in sparse_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2d9769fa-ae37-4a04-88d2-2c275a604864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'feat': 'weight'},\n",
       "  {'feat': 'last14max'},\n",
       "  {'feat': 'last14min'},\n",
       "  {'feat': 'last14std'},\n",
       "  {'feat': 'last14mean'},\n",
       "  {'feat': 'last14median'},\n",
       "  {'feat': 'last14sum'},\n",
       "  {'feat': 'last7max'},\n",
       "  {'feat': 'last7min'},\n",
       "  {'feat': 'last7std'},\n",
       "  {'feat': 'last7mean'},\n",
       "  {'feat': 'last7median'},\n",
       "  {'feat': 'last7sum'},\n",
       "  {'feat': 'last3max'},\n",
       "  {'feat': 'last3min'},\n",
       "  {'feat': 'last3std'},\n",
       "  {'feat': 'last3mean'},\n",
       "  {'feat': 'last3median'},\n",
       "  {'feat': 'last3sum'},\n",
       "  {'feat': 'last3value'},\n",
       "  {'feat': 'last1value'},\n",
       "  {'feat': 'last2mean'},\n",
       "  {'feat': 'last2sum'},\n",
       "  {'feat': 'last2value'},\n",
       "  {'feat': 'geo1mean14'},\n",
       "  {'feat': 'geo2mean14'},\n",
       "  {'feat': 'geo3mean14'},\n",
       "  {'feat': 'pro1mean14'},\n",
       "  {'feat': 'pro2mean14'},\n",
       "  {'feat': 'geo1median14'},\n",
       "  {'feat': 'geo2median14'},\n",
       "  {'feat': 'geo3median14'},\n",
       "  {'feat': 'pro1median14'},\n",
       "  {'feat': 'pro2median14'}],\n",
       " [{'feat': 'unit', 'feat_num': 632, 'embed_dim': 32},\n",
       "  {'feat': 'year', 'feat_num': 4, 'embed_dim': 32},\n",
       "  {'feat': 'month', 'feat_num': 12, 'embed_dim': 32},\n",
       "  {'feat': 'day', 'feat_num': 31, 'embed_dim': 32},\n",
       "  {'feat': 'week', 'feat_num': 7, 'embed_dim': 32},\n",
       "  {'feat': 'geography_level_1', 'feat_num': 8, 'embed_dim': 32},\n",
       "  {'feat': 'geography_level_2', 'feat_num': 26, 'embed_dim': 32},\n",
       "  {'feat': 'geography_level_3', 'feat_num': 81, 'embed_dim': 32},\n",
       "  {'feat': 'product_level_1', 'feat_num': 4, 'embed_dim': 32},\n",
       "  {'feat': 'product_level_2', 'feat_num': 19, 'embed_dim': 32},\n",
       "  {'feat': 'unit_pro', 'feat_num': 632, 'embed_dim': 32},\n",
       "  {'feat': 'geo_pro', 'feat_num': 553, 'embed_dim': 32}]]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "587e592d-9d2b-4679-975c-19ce8501576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "train = dataset[dataset.ts <= pd.to_datetime(\"20210301\")]\n",
    "test = dataset[dataset.ts > pd.to_datetime(\"20210301\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5ad57249-f728-43db-a22e-63a54bd98552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>unit</th>\n",
       "      <th>qty</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>geography_level_1</th>\n",
       "      <th>geography_level_2</th>\n",
       "      <th>geography_level_3</th>\n",
       "      <th>...</th>\n",
       "      <th>geo1mean14</th>\n",
       "      <th>geo2mean14</th>\n",
       "      <th>geo3mean14</th>\n",
       "      <th>pro1mean14</th>\n",
       "      <th>pro2mean14</th>\n",
       "      <th>geo1median14</th>\n",
       "      <th>geo2median14</th>\n",
       "      <th>geo3median14</th>\n",
       "      <th>pro1median14</th>\n",
       "      <th>pro2median14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>386</td>\n",
       "      <td>1.206126</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9322.365600</td>\n",
       "      <td>9322.365600</td>\n",
       "      <td>10257.857667</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>9402.972200</td>\n",
       "      <td>9402.972200</td>\n",
       "      <td>11574.911600</td>\n",
       "      <td>7465.950400</td>\n",
       "      <td>7368.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>463</td>\n",
       "      <td>1.187046</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>11468.327400</td>\n",
       "      <td>6292.426600</td>\n",
       "      <td>6292.426600</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>9257.535400</td>\n",
       "      <td>6292.426600</td>\n",
       "      <td>6292.426600</td>\n",
       "      <td>7465.950400</td>\n",
       "      <td>7368.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>273</td>\n",
       "      <td>1.064226</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11468.327400</td>\n",
       "      <td>12503.507560</td>\n",
       "      <td>12786.431900</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>9257.535400</td>\n",
       "      <td>12262.244200</td>\n",
       "      <td>12769.131900</td>\n",
       "      <td>7465.950400</td>\n",
       "      <td>7368.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>520</td>\n",
       "      <td>1.186037</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>18160.977000</td>\n",
       "      <td>17557.108000</td>\n",
       "      <td>6594.245200</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>21302.775500</td>\n",
       "      <td>22596.567000</td>\n",
       "      <td>6594.245200</td>\n",
       "      <td>7465.950400</td>\n",
       "      <td>7368.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>480</td>\n",
       "      <td>1.213034</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>11336.220300</td>\n",
       "      <td>11336.220300</td>\n",
       "      <td>11336.220300</td>\n",
       "      <td>10866.343811</td>\n",
       "      <td>10826.978933</td>\n",
       "      <td>11335.320300</td>\n",
       "      <td>11335.320300</td>\n",
       "      <td>11335.320300</td>\n",
       "      <td>7465.950400</td>\n",
       "      <td>7368.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690701</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>302</td>\n",
       "      <td>1.096779</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>9615.112417</td>\n",
       "      <td>12070.701765</td>\n",
       "      <td>13556.944969</td>\n",
       "      <td>7594.989885</td>\n",
       "      <td>2795.366300</td>\n",
       "      <td>2784.529622</td>\n",
       "      <td>4174.833333</td>\n",
       "      <td>4981.666667</td>\n",
       "      <td>1698.166667</td>\n",
       "      <td>442.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691801</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>351</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>8800.525911</td>\n",
       "      <td>9400.703053</td>\n",
       "      <td>0.996365</td>\n",
       "      <td>2709.366586</td>\n",
       "      <td>885.418008</td>\n",
       "      <td>2163.780924</td>\n",
       "      <td>2375.538466</td>\n",
       "      <td>0.314670</td>\n",
       "      <td>946.840007</td>\n",
       "      <td>1027.680664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692901</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>581</td>\n",
       "      <td>1.104744</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8800.525911</td>\n",
       "      <td>9400.703053</td>\n",
       "      <td>13372.251816</td>\n",
       "      <td>492.584735</td>\n",
       "      <td>207.503153</td>\n",
       "      <td>2163.780924</td>\n",
       "      <td>2375.538466</td>\n",
       "      <td>2560.486654</td>\n",
       "      <td>107.227762</td>\n",
       "      <td>59.348614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694001</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>230</td>\n",
       "      <td>1.145573</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8800.525911</td>\n",
       "      <td>9400.703053</td>\n",
       "      <td>13372.251816</td>\n",
       "      <td>492.584735</td>\n",
       "      <td>777.666317</td>\n",
       "      <td>2163.780924</td>\n",
       "      <td>2375.538466</td>\n",
       "      <td>2560.486654</td>\n",
       "      <td>107.227762</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695101</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>43</td>\n",
       "      <td>0.905894</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>8800.525911</td>\n",
       "      <td>1963.704475</td>\n",
       "      <td>976.188856</td>\n",
       "      <td>7594.989885</td>\n",
       "      <td>29547.172619</td>\n",
       "      <td>2163.780924</td>\n",
       "      <td>1857.977973</td>\n",
       "      <td>975.620551</td>\n",
       "      <td>1698.166667</td>\n",
       "      <td>24166.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281489 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ts  unit       qty  year  month  day  week  geography_level_1  \\\n",
       "2      2018-06-06   386  1.206126     0      5    5     2                  5   \n",
       "1102   2018-06-06   463  1.187046     0      5    5     2                  0   \n",
       "2202   2018-06-06   273  1.064226     0      5    5     2                  0   \n",
       "3302   2018-06-06   520  1.186037     0      5    5     2                  1   \n",
       "4402   2018-06-06   480  1.213034     0      5    5     2                  7   \n",
       "...           ...   ...       ...   ...    ...  ...   ...                ...   \n",
       "690701 2021-03-01   302  1.096779     3      2    0     0                  0   \n",
       "691801 2021-03-01   351  0.022036     3      2    0     0                  1   \n",
       "692901 2021-03-01   581  1.104744     3      2    0     0                  1   \n",
       "694001 2021-03-01   230  1.145573     3      2    0     0                  1   \n",
       "695101 2021-03-01    43  0.905894     3      2    0     0                  1   \n",
       "\n",
       "        geography_level_2  geography_level_3  ...    geo1mean14    geo2mean14  \\\n",
       "2                      12                 11  ...   9322.365600   9322.365600   \n",
       "1102                    3                 75  ...  11468.327400   6292.426600   \n",
       "2202                   10                  7  ...  11468.327400  12503.507560   \n",
       "3302                   11                 23  ...  18160.977000  17557.108000   \n",
       "4402                    4                 76  ...  11336.220300  11336.220300   \n",
       "...                   ...                ...  ...           ...           ...   \n",
       "690701                  3                 75  ...   9615.112417  12070.701765   \n",
       "691801                 24                 31  ...   8800.525911   9400.703053   \n",
       "692901                 24                  1  ...   8800.525911   9400.703053   \n",
       "694001                 24                  1  ...   8800.525911   9400.703053   \n",
       "695101                  6                 78  ...   8800.525911   1963.704475   \n",
       "\n",
       "          geo3mean14    pro1mean14    pro2mean14  geo1median14  geo2median14  \\\n",
       "2       10257.857667  10866.343811  10826.978933   9402.972200   9402.972200   \n",
       "1102     6292.426600  10866.343811  10826.978933   9257.535400   6292.426600   \n",
       "2202    12786.431900  10866.343811  10826.978933   9257.535400  12262.244200   \n",
       "3302     6594.245200  10866.343811  10826.978933  21302.775500  22596.567000   \n",
       "4402    11336.220300  10866.343811  10826.978933  11335.320300  11335.320300   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "690701  13556.944969   7594.989885   2795.366300   2784.529622   4174.833333   \n",
       "691801      0.996365   2709.366586    885.418008   2163.780924   2375.538466   \n",
       "692901  13372.251816    492.584735    207.503153   2163.780924   2375.538466   \n",
       "694001  13372.251816    492.584735    777.666317   2163.780924   2375.538466   \n",
       "695101    976.188856   7594.989885  29547.172619   2163.780924   1857.977973   \n",
       "\n",
       "        geo3median14  pro1median14  pro2median14  \n",
       "2       11574.911600   7465.950400   7368.841600  \n",
       "1102     6292.426600   7465.950400   7368.841600  \n",
       "2202    12769.131900   7465.950400   7368.841600  \n",
       "3302     6594.245200   7465.950400   7368.841600  \n",
       "4402    11335.320300   7465.950400   7368.841600  \n",
       "...              ...           ...           ...  \n",
       "690701   4981.666667   1698.166667    442.166667  \n",
       "691801      0.314670    946.840007   1027.680664  \n",
       "692901   2560.486654    107.227762     59.348614  \n",
       "694001   2560.486654    107.227762    500.000000  \n",
       "695101    975.620551   1698.166667  24166.666667  \n",
       "\n",
       "[281489 rows x 48 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ae6bf8c6-9295-4b23-bf47-28c4424a03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train:(281489, 48)\n",
      "The shape of X_test:(61936, 48)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of X_train:{}'.format(train.shape))\n",
    "print('The shape of X_test:{}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "87b02640-00fd-4b37-929f-9dfa8acc6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "train_X = [train[dense_features].values, train[sparse_features].values.astype('int32')]\n",
    "train_y = train[target].values.astype('int32')\n",
    "test_X = [test[dense_features].values, test[sparse_features].values.astype('int32')]\n",
    "test_y = test[target].values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "28a4b6ea-b64e-49b3-8e51-1179343419bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Dense, Input, Layer\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9c4b7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Layer):\n",
    "\tdef __init__(self, k=10, w_reg=1e-4, v_reg=1e-4):\n",
    "\t\t\"\"\"\n",
    "\t\tFactorization Machine\n",
    "\t\t:param k: A scalar. The dimension of the latent vector.\n",
    "\t\t:param w_reg: A scalar. The regularization coefficient of parameter w.\n",
    "\t\t:param v_reg: A scalar. The regularization coefficient of parameter v.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(FM, self).__init__()\n",
    "\t\tself.k = k  # 定义隐藏层的层数\n",
    "\t\tself.w_reg = w_reg  # 参数 w 的正则化系数\n",
    "\t\tself.v_reg = v_reg  # 参数 v 的正则化系数\n",
    "\n",
    "\tdef build(self, input_shape):\n",
    "\t\tself.w0 = self.add_weight(name='w0', shape=(1,),\n",
    "\t\t\t\t\t\t\t\t  initializer=tf.zeros_initializer(),\n",
    "\t\t\t\t\t\t\t\t  trainable=True)\n",
    "\t\tself.w = self.add_weight(name='w', shape=(input_shape[-1], 1),\n",
    "\t\t\t\t\t\t\t\t initializer='random_uniform',\n",
    "\t\t\t\t\t\t\t\t regularizer=l2(self.w_reg),\n",
    "\t\t\t\t\t\t\t\t trainable=True)\n",
    "\t\tself.V = self.add_weight(name='V', shape=(self.k, input_shape[-1]),\n",
    "\t\t\t\t\t\t\t\t initializer='random_uniform',\n",
    "\t\t\t\t\t\t\t\t regularizer=l2(self.v_reg),\n",
    "\t\t\t\t\t\t\t\t trainable=True)\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\t# first order\n",
    "\t\tfirst_order = self.w0 + tf.matmul(inputs, self.w)\n",
    "\t\t# second order\n",
    "\t\tsecond_order = 0.5 * tf.reduce_sum(\n",
    "\t\t\ttf.pow(tf.matmul(inputs, tf.transpose(self.V)), 2) -\n",
    "\t\t\ttf.matmul(tf.pow(inputs, 2), tf.pow(tf.transpose(self.V), 2)), axis=1, keepdims=True)\n",
    "\t\treturn first_order + second_order\n",
    "\n",
    "\n",
    "class DNN(Layer):\n",
    "\t\"\"\"\n",
    "\tDeep part\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, hidden_units, activation='relu', dnn_dropout=0.):\n",
    "\t\t\"\"\"\n",
    "\t\tDNN part\n",
    "\t\t:param hidden_units: A list. List of hidden layer units's numbers\n",
    "\t\t:param activation: A string. Activation function\n",
    "\t\t:param dnn_dropout: A scalar. dropout number\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(DNN, self).__init__()\n",
    "\t\tself.dnn_network = [Dense(units=unit, activation=activation) for unit in hidden_units]\n",
    "\t\tself.dropout = Dropout(dnn_dropout)\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tx = inputs\n",
    "\t\tfor dnn in self.dnn_network:\n",
    "\t\t\tx = dnn(x)\n",
    "\t\tx = self.dropout(x)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "class DeepFM(keras.Model):\n",
    "\tdef __init__(self, feature_columns, k=10, hidden_units=(200, 200, 200), dnn_dropout=0.,\n",
    "\t\t\t\t activation='relu', fm_w_reg=1e-4, fm_v_reg=1e-4, embed_reg=1e-4):\n",
    "\t\t\"\"\"\n",
    "\t\tDeepFM\n",
    "\t\t:param feature_columns: A list. a list containing dense and sparse column feature information.\n",
    "\t\t:param k: A scalar. fm's latent vector number.\n",
    "\t\t:param hidden_units: A list. A list of dnn hidden units.\n",
    "\t\t:param dnn_dropout: A scalar. Dropout of dnn.\n",
    "\t\t:param activation: A string. Activation function of dnn.\n",
    "\t\t:param fm_w_reg: A scalar. The regularizer of w in fm.\n",
    "\t\t:param fm_v_reg: A scalar. The regularizer of v in fm.\n",
    "\t\t:param embed_reg: A scalar. The regularizer of embedding.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(DeepFM, self).__init__()\n",
    "\t\tself.dense_feature_columns, self.sparse_feature_columns = feature_columns  # feature_columns是被分成了稠密和稀疏特征\n",
    "\t\t# 对稀疏特征sparse_feature_columns进行embedding处理，每一列转化成embedding==8的列向量\n",
    "\t\tself.embed_layers = {\n",
    "\t\t\t'embed_' + str(i): Embedding(input_dim=feat['feat_num'],\n",
    "\t\t\t\t\t\t\t\t\t\t input_length=1,\n",
    "\t\t\t\t\t\t\t\t\t\t output_dim=feat['embed_dim'],\n",
    "\t\t\t\t\t\t\t\t\t\t embeddings_initializer='random_uniform',\n",
    "\t\t\t\t\t\t\t\t\t\t embeddings_regularizer=l2(embed_reg))\n",
    "\t\t\tfor i, feat in enumerate(self.sparse_feature_columns)\n",
    "\t\t}\n",
    "\t\tself.fm = FM(k, fm_w_reg, fm_v_reg)\n",
    "\t\tself.dnn = DNN(hidden_units, activation, dnn_dropout)\n",
    "\t\tself.dense = Dense(1, activation=None)\n",
    "\n",
    "\tdef call(self, inputs, **kwargs):\n",
    "\t\tdense_inputs, sparse_inputs = inputs\n",
    "\t\t# sparse_inputs.shape[1] == 26 遍历26个“稀疏”特征，并将其转化成 embedding ==8 的这个特征的域，\n",
    "\t\t# 最后，将这些特征进行拼接  208 = 26*8\n",
    "\t\tsparse_embed = tf.concat([self.embed_layers['embed_{}'.format(i)](sparse_inputs[:, i])\n",
    "                                  for i in range(sparse_inputs.shape[1])], axis=-1)   # shape=(None,208)\n",
    "\t\tstack = tf.concat([dense_inputs, sparse_embed], axis=-1)\n",
    "\t\t# wide\n",
    "\t\twide_outputs = self.fm(stack)  # shape=(none,1)\n",
    "\t\t# deep\n",
    "\t\tdeep_outputs = self.dnn(stack)  # shape=(none,64)\n",
    "\t\tdeep_outputs = self.dense(deep_outputs)  # shape=(none,1)\n",
    "\n",
    "\t\toutputs = tf.nn.sigmoid(tf.add(wide_outputs, deep_outputs))\n",
    "\t\treturn outputs\n",
    "\n",
    "\tdef summary(self):\n",
    "\t\tdense_inputs = Input(shape=(len(self.dense_feature_columns),), dtype=tf.float32)\n",
    "\t\tsparse_inputs = Input(shape=(len(self.sparse_feature_columns),), dtype=tf.int32)\n",
    "\t\tkeras.Model(inputs=[dense_inputs, sparse_inputs], outputs=self.call([dense_inputs, sparse_inputs])).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "750065fe-c6b9-4286-a625-630d3f6cdf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# tf.test.is_gpu_available(cuda_only=True)\n",
    "\n",
    "gpu = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "02524970-72ad-4fe9-96a6-57f4c7e7e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2286737d-a72f-4ccc-a38b-9f03742e14a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_132 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_133 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_134 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_135 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_136 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_137 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_138 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_139 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_140 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_141 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_142 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_143 (S (None,)              0           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_132 (Embedding)       (None, 32)           20224       tf.__operators__.getitem_132[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_133 (Embedding)       (None, 32)           128         tf.__operators__.getitem_133[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_134 (Embedding)       (None, 32)           384         tf.__operators__.getitem_134[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_135 (Embedding)       (None, 32)           992         tf.__operators__.getitem_135[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_136 (Embedding)       (None, 32)           224         tf.__operators__.getitem_136[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_137 (Embedding)       (None, 32)           256         tf.__operators__.getitem_137[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_138 (Embedding)       (None, 32)           832         tf.__operators__.getitem_138[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_139 (Embedding)       (None, 32)           2592        tf.__operators__.getitem_139[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_140 (Embedding)       (None, 32)           128         tf.__operators__.getitem_140[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_141 (Embedding)       (None, 32)           608         tf.__operators__.getitem_141[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_142 (Embedding)       (None, 32)           20224       tf.__operators__.getitem_142[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_143 (Embedding)       (None, 32)           17696       tf.__operators__.getitem_143[0][0\n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 34)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_22 (TFOpLambda)       (None, 384)          0           embedding_132[0][0]              \n",
      "                                                                 embedding_133[0][0]              \n",
      "                                                                 embedding_134[0][0]              \n",
      "                                                                 embedding_135[0][0]              \n",
      "                                                                 embedding_136[0][0]              \n",
      "                                                                 embedding_137[0][0]              \n",
      "                                                                 embedding_138[0][0]              \n",
      "                                                                 embedding_139[0][0]              \n",
      "                                                                 embedding_140[0][0]              \n",
      "                                                                 embedding_141[0][0]              \n",
      "                                                                 embedding_142[0][0]              \n",
      "                                                                 embedding_143[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_23 (TFOpLambda)       (None, 418)          0           input_23[0][0]                   \n",
      "                                                                 tf.concat_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dnn_11 (DNN)                    (None, 64)           148416      tf.concat_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fm_11 (FM)                      (None, 1)            4599        tf.concat_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 1)            65          dnn_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_11 (TFOpLambda)     (None, 1)            0           fm_11[0][0]                      \n",
      "                                                                 dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_11 (TFOpLambda) (None, 1)            0           tf.math.add_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 217,368\n",
      "Trainable params: 217,368\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "read_part = True\n",
    "sample_num = 600000\n",
    "test_size = 0.2\n",
    "\n",
    "embed_dim = 32\n",
    "k = 10\n",
    "dnn_dropout = 0.1\n",
    "hidden_units = [256, 128, 64]\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "model = DeepFM(feature_columns, k=k, hidden_units=hidden_units, dnn_dropout=dnn_dropout)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "96bf444b-d660-4c31-841a-cfc98e5ce15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def custom_loss(y_actual, y_pred):\n",
    "    y_actual = tf.cast(y_actual,dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred,dtype=tf.float32)\n",
    "    custom_loss= (y_actual - y_pred)**2\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "42dd18f7-ff8d-41a7-82ca-02f794398c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "254/254 [==============================] - 4s 8ms/step - loss: 0.2510 - mse: 0.2506 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 2/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 3/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 4/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 5/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 6/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 7/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 8/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 9/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 10/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 11/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 12/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 13/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 14/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 15/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 16/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 17/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 18/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 19/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 20/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1420 - mse: 0.1419 - val_loss: 0.1192 - val_mse: 0.1192\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 21/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0956 - mse: 0.0955 - val_loss: 0.1085 - val_mse: 0.1085\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 22/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1269 - mse: 0.1269 - val_loss: 0.1566 - val_mse: 0.1565\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 23/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1319 - mse: 0.1319 - val_loss: 0.1566 - val_mse: 0.1565\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 24/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1390 - mse: 0.1390 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 25/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 26/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 27/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 28/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 29/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 30/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 31/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 32/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 33/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 34/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 35/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 36/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 37/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 38/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 39/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 40/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 41/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 42/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 43/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 44/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 45/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1477 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 46/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 47/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 48/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 49/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 50/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 51/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 52/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 53/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1322 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 54/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1478 - mse: 0.1477 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 55/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 0.1112 - val_mse: 0.1112\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 56/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0912 - mse: 0.0912 - val_loss: 0.1153 - val_mse: 0.1153\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 57/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.1168 - val_mse: 0.1167\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 58/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0932 - mse: 0.0932 - val_loss: 0.1181 - val_mse: 0.1181\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 59/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.1187 - val_mse: 0.1187\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 60/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0953 - mse: 0.0953 - val_loss: 0.1187 - val_mse: 0.1187\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 61/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 0.1192 - val_mse: 0.1192\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 62/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0982 - mse: 0.0981 - val_loss: 0.1220 - val_mse: 0.1220\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 63/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1008 - mse: 0.1007 - val_loss: 0.1211 - val_mse: 0.1210\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 64/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1240 - mse: 0.1239 - val_loss: 0.0928 - val_mse: 0.0927\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 65/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1002 - mse: 0.1001 - val_loss: 0.0928 - val_mse: 0.0928\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 66/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0995 - mse: 0.0994 - val_loss: 0.0897 - val_mse: 0.0896\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 67/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 0.0896 - val_mse: 0.0895\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 68/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0945 - mse: 0.0944 - val_loss: 0.0896 - val_mse: 0.0895\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 69/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0943 - mse: 0.0942 - val_loss: 0.0896 - val_mse: 0.0895\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 70/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0943 - mse: 0.0942 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 71/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0941 - mse: 0.0940 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 72/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.0940 - mse: 0.0939 - val_loss: 0.0895 - val_mse: 0.0895\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 73/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1199 - mse: 0.1198 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 74/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 75/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 76/100\n",
      "254/254 [==============================] - 2s 6ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 77/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 78/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 79/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 80/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 81/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 82/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 83/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 84/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 85/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 86/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 87/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 88/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 89/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 90/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 91/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 92/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 93/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 94/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 95/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 96/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 97/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 98/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 99/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n",
      "Epoch 100/100\n",
      "254/254 [==============================] - 2s 7ms/step - loss: 0.1480 - mse: 0.1479 - val_loss: 0.1323 - val_mse: 0.1321\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,mse,val_loss,val_mse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f23820b1610>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================model checkpoint======================\n",
    "check_path = '../output/deepfm/deepfm_weights.epoch_{epoch:04d}.val_loss_{val_loss:.4f}.ckpt'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(check_path, save_weights_only=True,\n",
    "                                                verbose=1, period=5)\n",
    "\n",
    "# ============================Compile============================\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='Adam',\n",
    "              metrics=['mse'])\n",
    "# ==============================Fit==============================\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', min_delta=0.01,\n",
    "                                                  patience=1, verbose=0, mode='max',\n",
    "                                                  baseline=None, restore_best_weights=True)\n",
    "model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cd46fada-bd69-4f0e-b2a8-6a4e74e5968f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trian' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [167]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ===========================Test==============================\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrian\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trian' is not defined"
     ]
    }
   ],
   "source": [
    "# ===========================Test==============================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d3225492-d4e9-4525-9efb-6a3605fb95ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(test_X)\n",
    "prediction = prediction[:, 0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "441b503a-2eeb-4c9a-af49-d0b2e516d778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[7.90000000e-02, 4.19429308e+00, 4.19005222e+00, ...,\n",
       "         3.75852080e+00, 4.22650943e+00, 4.22074205e+00],\n",
       "        [2.05000000e-01, 4.61495968e+00, 4.60811857e+00, ...,\n",
       "         3.69731654e+00, 4.22650943e+00, 4.22074205e+00],\n",
       "        [1.00000000e-02, 3.25761355e+00, 3.24445748e+00, ...,\n",
       "         3.85859734e+00, 4.22650943e+00, 4.22074205e+00],\n",
       "        ...,\n",
       "        [4.00000000e-03, 2.91860004e+00, 2.90024427e+00, ...,\n",
       "         3.46725788e+00, 2.21583215e+00, 1.94734920e+00],\n",
       "        [1.00000000e-02, 3.30133751e+00, 3.29067445e+00, ...,\n",
       "         3.46725788e+00, 2.21583215e+00, 2.74024752e+00],\n",
       "        [1.00000000e-03, 1.47712125e+00, 1.47712125e+00, ...,\n",
       "         2.96951227e+00, 3.29531048e+00, 4.40021841e+00]]),\n",
       " array([[ 386,    3,    2, ...,    6,  761,   85],\n",
       "        [ 463,    3,    2, ...,    6,  913,  518],\n",
       "        [ 273,    3,    2, ...,    6,  537,   54],\n",
       "        ...,\n",
       "        [ 581,    3,    5, ...,   14, 1144,    9],\n",
       "        [ 230,    3,    5, ...,   16,  451,   10],\n",
       "        [  43,    3,    5, ...,   10,   84,  546]], dtype=int32)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "287216d9-f6e2-4f12-8020-bb81cd0c9bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.30069111e-28 0.00000000e+00 8.53590640e-28 ... 1.18498085e-11\n",
      " 3.41056480e-12 9.22822027e-19]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction = prediction * (max_value - min_value) + min_value\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "310f76d7-2653-4002-8950-415f9ba7aa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>unit</th>\n",
       "      <th>qty</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>geography_level_1</th>\n",
       "      <th>geography_level_2</th>\n",
       "      <th>geography_level_3</th>\n",
       "      <th>...</th>\n",
       "      <th>geo1mean14</th>\n",
       "      <th>geo2mean14</th>\n",
       "      <th>geo3mean14</th>\n",
       "      <th>pro1mean14</th>\n",
       "      <th>pro2mean14</th>\n",
       "      <th>geo1median14</th>\n",
       "      <th>geo2median14</th>\n",
       "      <th>geo3median14</th>\n",
       "      <th>pro1median14</th>\n",
       "      <th>pro2median14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>386</td>\n",
       "      <td>0.082403</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095559</td>\n",
       "      <td>0.191889</td>\n",
       "      <td>0.189043</td>\n",
       "      <td>0.942393</td>\n",
       "      <td>0.582141</td>\n",
       "      <td>0.017207</td>\n",
       "      <td>0.057115</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.929982</td>\n",
       "      <td>0.591379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>463</td>\n",
       "      <td>0.215954</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261972</td>\n",
       "      <td>0.465002</td>\n",
       "      <td>0.332678</td>\n",
       "      <td>0.942393</td>\n",
       "      <td>0.582141</td>\n",
       "      <td>0.074577</td>\n",
       "      <td>0.154936</td>\n",
       "      <td>0.137140</td>\n",
       "      <td>0.929982</td>\n",
       "      <td>0.591379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>273</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261972</td>\n",
       "      <td>0.459282</td>\n",
       "      <td>0.275656</td>\n",
       "      <td>0.942393</td>\n",
       "      <td>0.582141</td>\n",
       "      <td>0.074577</td>\n",
       "      <td>0.125657</td>\n",
       "      <td>0.198826</td>\n",
       "      <td>0.929982</td>\n",
       "      <td>0.591379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>520</td>\n",
       "      <td>0.193414</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239564</td>\n",
       "      <td>0.335753</td>\n",
       "      <td>0.346706</td>\n",
       "      <td>0.942393</td>\n",
       "      <td>0.582141</td>\n",
       "      <td>0.057175</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>0.081557</td>\n",
       "      <td>0.929982</td>\n",
       "      <td>0.591379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>480</td>\n",
       "      <td>0.088937</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117522</td>\n",
       "      <td>0.167663</td>\n",
       "      <td>0.178408</td>\n",
       "      <td>0.942393</td>\n",
       "      <td>0.582141</td>\n",
       "      <td>0.032125</td>\n",
       "      <td>0.046260</td>\n",
       "      <td>0.090576</td>\n",
       "      <td>0.929982</td>\n",
       "      <td>0.591379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690799</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>302</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276594</td>\n",
       "      <td>0.534210</td>\n",
       "      <td>0.397432</td>\n",
       "      <td>0.364165</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>0.072710</td>\n",
       "      <td>0.196279</td>\n",
       "      <td>0.162815</td>\n",
       "      <td>0.105866</td>\n",
       "      <td>0.033127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691899</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>351</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253345</td>\n",
       "      <td>0.375334</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.114570</td>\n",
       "      <td>0.071417</td>\n",
       "      <td>0.067160</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.061226</td>\n",
       "      <td>0.099296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692999</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>581</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253345</td>\n",
       "      <td>0.375334</td>\n",
       "      <td>0.321470</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.009026</td>\n",
       "      <td>0.067160</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>0.080732</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694099</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>230</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253345</td>\n",
       "      <td>0.375334</td>\n",
       "      <td>0.321470</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>0.067160</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>0.080732</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.019526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695199</th>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253345</td>\n",
       "      <td>0.082167</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>0.364165</td>\n",
       "      <td>0.907925</td>\n",
       "      <td>0.067160</td>\n",
       "      <td>0.075510</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.105866</td>\n",
       "      <td>0.894028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61936 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ts  unit       qty  year  month  day  week  geography_level_1  \\\n",
       "1002   2021-03-02   386  0.082403     3      2    1     1                  5   \n",
       "2102   2021-03-02   463  0.215954     3      2    1     1                  0   \n",
       "3202   2021-03-02   273  0.009601     3      2    1     1                  0   \n",
       "4302   2021-03-02   520  0.193414     3      2    1     1                  1   \n",
       "5402   2021-03-02   480  0.088937     3      2    1     1                  7   \n",
       "...           ...   ...       ...   ...    ...  ...   ...                ...   \n",
       "690799 2021-06-07   302  0.007711     3      5    6     0                  0   \n",
       "691899 2021-06-07   351  0.000543     3      5    6     0                  1   \n",
       "692999 2021-06-07   581  0.004315     3      5    6     0                  1   \n",
       "694099 2021-06-07   230  0.010314     3      5    6     0                  1   \n",
       "695199 2021-06-07    43  0.000153     3      5    6     0                  1   \n",
       "\n",
       "        geography_level_2  geography_level_3  ...  geo1mean14  geo2mean14  \\\n",
       "1002                   12                 11  ...    0.095559    0.191889   \n",
       "2102                    3                 75  ...    0.261972    0.465002   \n",
       "3202                   10                  7  ...    0.261972    0.459282   \n",
       "4302                   11                 23  ...    0.239564    0.335753   \n",
       "5402                    4                 76  ...    0.117522    0.167663   \n",
       "...                   ...                ...  ...         ...         ...   \n",
       "690799                  3                 75  ...    0.276594    0.534210   \n",
       "691899                 24                 31  ...    0.253345    0.375334   \n",
       "692999                 24                  1  ...    0.253345    0.375334   \n",
       "694099                 24                  1  ...    0.253345    0.375334   \n",
       "695199                  6                 78  ...    0.253345    0.082167   \n",
       "\n",
       "        geo3mean14  pro1mean14  pro2mean14  geo1median14  geo2median14  \\\n",
       "1002      0.189043    0.942393    0.582141      0.017207      0.057115   \n",
       "2102      0.332678    0.942393    0.582141      0.074577      0.154936   \n",
       "3202      0.275656    0.942393    0.582141      0.074577      0.125657   \n",
       "4302      0.346706    0.942393    0.582141      0.057175      0.081171   \n",
       "5402      0.178408    0.942393    0.582141      0.032125      0.046260   \n",
       "...            ...         ...         ...           ...           ...   \n",
       "690799    0.397432    0.364165    0.100976      0.072710      0.196279   \n",
       "691899    0.000647    0.114570    0.071417      0.067160      0.099023   \n",
       "692999    0.321470    0.007917    0.009026      0.067160      0.099023   \n",
       "694099    0.321470    0.007917    0.026522      0.067160      0.099023   \n",
       "695199    0.023058    0.364165    0.907925      0.067160      0.075510   \n",
       "\n",
       "        geo3median14  pro1median14  pro2median14  \n",
       "1002        0.157900      0.929982      0.591379  \n",
       "2102        0.137140      0.929982      0.591379  \n",
       "3202        0.198826      0.929982      0.591379  \n",
       "4302        0.081557      0.929982      0.591379  \n",
       "5402        0.090576      0.929982      0.591379  \n",
       "...              ...           ...           ...  \n",
       "690799      0.162815      0.105866      0.033127  \n",
       "691899      0.000038      0.061226      0.099296  \n",
       "692999      0.080732      0.005601      0.003116  \n",
       "694099      0.080732      0.005601      0.019526  \n",
       "695199      0.025644      0.105866      0.894028  \n",
       "\n",
       "[61936 rows x 48 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c247a088-d9a3-4206-9172-0c750c8ec4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 21 16:03:07 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           On   | 00000000:00:0B.0 Off |                    0 |\n",
      "| N/A   35C    P0    49W / 250W |  22496MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           On   | 00000000:00:0C.0 Off |                    0 |\n",
      "| N/A   28C    P0    50W / 250W |    267MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P40           On   | 00000000:00:0D.0 Off |                    0 |\n",
      "| N/A   27C    P0    50W / 250W |    267MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P40           On   | 00000000:00:0E.0 Off |                    0 |\n",
      "| N/A   37C    P0    49W / 250W |    267MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     12106      C   ...nda3/envs/py38/bin/python    20557MiB |\n",
      "|    0   N/A  N/A     39427      C   ...onda3/envs/nlp/bin/python     1937MiB |\n",
      "|    1   N/A  N/A     12106      C   ...nda3/envs/py38/bin/python      265MiB |\n",
      "|    2   N/A  N/A     12106      C   ...nda3/envs/py38/bin/python      265MiB |\n",
      "|    3   N/A  N/A     12106      C   ...nda3/envs/py38/bin/python      265MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7345089a-0670-4d14-aab5-7f4f9707582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 12106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88187e29-b577-4000-a329-461e41dd518f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 21 17:17:51 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P40           On   | 00000000:00:0B.0 Off |                    0 |\n",
      "| N/A   34C    P0    49W / 250W |   1939MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P40           On   | 00000000:00:0C.0 Off |                    0 |\n",
      "| N/A   21C    P8     9W / 250W |      2MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P40           On   | 00000000:00:0D.0 Off |                    0 |\n",
      "| N/A   20C    P8     9W / 250W |      2MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P40           On   | 00000000:00:0E.0 Off |                    0 |\n",
      "| N/A   26C    P8     9W / 250W |      2MiB / 22919MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     39427      C   ...onda3/envs/nlp/bin/python     1937MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e67a85-23db-427d-b71a-24a593aaeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 6759"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b2c99-483c-408c-aeb3-cd009d5c472f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
