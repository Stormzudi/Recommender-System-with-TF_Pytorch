## 案例--基于协同过滤的电影推荐

前面我们已经基本掌握了协同过滤推荐算法，以及其中两种最基本的实现方案：User-Based CF和Item-Based CF，下面我们将利用真是的数据来进行实战演练。

案例需求 演示效果

分析案例

#### 数据集下载

[MovieLens Latest Datasets Small](https://grouplens.org/datasets/movielens/latest/)

建议下载[ml-latest-small.zip](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip)，数据量小，便于我们单机使用和运行

目标：根据`ml-latest-small/ratings.csv`（用户-电影评分数据），分别实现User-Based CF和Item-Based CF，并进行电影评分的预测，然后为用户实现电影推荐

#### 数据集加载

- 加载ratings.csv，并转换为用户-电影评分矩阵

  ```python
  import os
  
  import pandas as pd
  import numpy as np
  
  DATA_PATH = "./datasets/ml-latest-small/ratings.csv"
  CACHE_DIR = "./datasets/cache/"
  
  def load_data(data_path):
      '''
      加载数据
      :param data_path: 数据集路径
      :param cache_path: 数据集缓存路径
      :return: 用户-物品评分矩阵
      '''
      # 数据集缓存地址
      cache_path = os.path.join(CACHE_DIR, "ratings_matrix.cache")
  
      print("开始加载数据集...")
      if os.path.exists(cache_path):    # 判断是否存在缓存文件
          print("加载缓存中...")
          ratings_matrix = pd.read_pickle(cache_path)
          print("从缓存加载数据集完毕")
      else:
          print("加载新数据中...")
          # 设置要加载的数据字段的类型
          dtype = {"userId": np.int32, "movieId": np.int32, "rating": np.float32}
          # 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分
          ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(3))
          # 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵
          ratings_matrix = ratings.pivot_table(index=["userId"], columns=["movieId"], values="rating")
          # 存入缓存文件
          ratings_matrix.to_pickle(cache_path)
          print("数据集加载完毕")
      return  ratings_matrix
  
  if __name__ == '__main__':
      ratings_matrix = load_data(DATA_PATH)
      print(ratings_matrix)
  ```

#### 相似度计算

- 计算用户或物品两两相似度：

  ```python
  # ......
  
  def compute_pearson_similarity(ratings_matrix, based="user"):
      '''
      计算皮尔逊相关系数
      :param ratings_matrix: 用户-物品评分矩阵
      :param based: "user" or "item"
      :return: 相似度矩阵
      '''
      user_similarity_cache_path = os.path.join(CACHE_DIR, "user_similarity.cache")
      item_similarity_cache_path = os.path.join(CACHE_DIR, "item_similarity.cache")
      # 基于皮尔逊相关系数计算相似度
      # 用户相似度
      if based == "user":
          if os.path.exists(user_similarity_cache_path):
              print("正从缓存加载用户相似度矩阵")
              similarity = pd.read_pickle(user_similarity_cache_path)
          else:
              print("开始计算用户相似度矩阵")
              similarity = ratings_matrix.T.corr()
              similarity.to_pickle(user_similarity_cache_path)
  
      elif based == "item":
          if os.path.exists(item_similarity_cache_path):
              print("正从缓存加载物品相似度矩阵")
              similarity = pd.read_pickle(item_similarity_cache_path)
          else:
              print("开始计算物品相似度矩阵")
              similarity = ratings_matrix.corr()
              similarity.to_pickle(item_similarity_cache_path)
      else:
          raise Exception("Unhandled 'based' Value: %s"%based)
      print("相似度矩阵计算/加载完毕")
      return similarity
  
  if __name__ == '__main__':
  
      ratings_matrix = load_data(DATA_PATH)
  
      user_similar = compute_pearson_similarity(ratings_matrix, based="user")
      print(user_similar)
      item_similar = compute_pearson_similarity(ratings_matrix, based="item")
      print(item_similar)
  ```

  

#### 注意

以上实现，仅用于实验阶段，因为工业上、或生产环境中，数据量是远超过我们本例中使用的数据量的，而pandas是无法支撑起大批量数据的运算的，因此工业上通常会使用spark、mapReduce等分布式计算框架来实现，我们后面的课程中也是建立在此基础上进行实践的。

但是正如前面所说，推荐算法的思想和理念都是统一的，不论使用什么平台工具、有多大的数据体量，其背后的实现原理都是不变的。

所以在本节，大家要深刻去学习的是推荐算法的业务流程，以及在具体的业务场景中，如本例的电影推荐，如何实现出推荐算法，并产生推荐结果。

